{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56be91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a857f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['recommender_system']\n",
    "admissions = db['admissions']\n",
    "patients = db['patients']\n",
    "diagnoses_icd = db['diagnoses_icd']\n",
    "procedures_icd = db['procedures_icd']\n",
    "d_icd_diagnoses = db['d_icd_diagnoses']\n",
    "d_icd_procedures = db['d_icd_procedures']\n",
    "nies = db['nies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813166ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admissions = pd.DataFrame(list(admissions.find()))\n",
    "df_patients = pd.DataFrame(list(patients.find()))\n",
    "df_diagnoses_icd = pd.DataFrame(list(diagnoses_icd.find()))\n",
    "df_procedures_icd = pd.DataFrame(list(procedures_icd.find()))\n",
    "df_d_icd_diagnoses = pd.DataFrame(list(d_icd_diagnoses.find()))\n",
    "df_d_icd_procedures = pd.DataFrame(list(d_icd_procedures.find()))\n",
    "df_nies = pd.DataFrame(list(nies.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27d3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(df_admissions, df_patients, on='subject_id', how='left')\n",
    "diagnoses_merged = pd.merge(merged_data, df_diagnoses_icd, on=['hadm_id', 'subject_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a45829",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_to_category = {\n",
    "    '250': 'Q45_QO9',  # Diabetes and related problems\n",
    "    '390-459': 'Q45_QO2',  # Heart condition\n",
    "    '460-519': 'Q45_QO3',  # Lung condition\n",
    "    '320-389': 'Q45_QO4',  # Neurological condition\n",
    "    '710-739': 'Q45_QO5',  # Orthopaedic condition\n",
    "    'U07.1': 'Q45_QO6',  # COVID-19\n",
    "    '001-139': 'Q45_QO7',  # Infection (other than COVID-19)\n",
    "    '520-579': 'Q45_QO8',  # Digestive system condition\n",
    "    '140-239': 'Q45_QO1',  # Tumour or cancer\n",
    "    '960-989': 'Q45_QO10',  # Adverse reaction or poisoning\n",
    "    '800-999': 'Q45_QO11',  # Injury and or accident\n",
    "    '290-319': 'Q45_QO12',  # Mental health issue\n",
    "    'V01-V91': 'Q45_QO13',  # Tests and or investigations\n",
    "    'Unknown': 'Q45_QO14'  # Dont know or wasnt told\n",
    "}\n",
    "category_labels = {\n",
    "    'Q45_QO1': 'Tumour or cancer',\n",
    "    'Q45_QO2': 'Heart condition',\n",
    "    'Q45_QO3': 'Lung condition',\n",
    "    'Q45_QO4': 'Neurological condition',\n",
    "    'Q45_QO5': 'Orthopaedic condition',\n",
    "    'Q45_QO6': 'COVID 19',\n",
    "    'Q45_QO7': 'Infection (other than COVID 19)',\n",
    "    'Q45_QO8': 'Digestive system condition',\n",
    "    'Q45_QO9': 'Diabetes and related problems',\n",
    "    'Q45_QO10': 'Adverse reaction or poising',\n",
    "    'Q45_QO11': 'Injury and or accident',\n",
    "    'Q45_QO12': 'Mental health issue',\n",
    "    'Q45_QO13': 'Tests and or investigations',\n",
    "    'Q45_QO14': 'Dont know or wasnt told',\n",
    "    'Q45_QO15': 'Other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99d387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_diagnosis(icd_code):\n",
    "    if pd.isna(icd_code):\n",
    "        return category_labels['Q45_QO15']\n",
    "    for code_range, category in icd_to_category.items():\n",
    "        if '-' in code_range:\n",
    "            start, end = code_range.split('-')\n",
    "            try:\n",
    "                if start <= str(icd_code) <= end:\n",
    "                    return category_labels[category]\n",
    "            except:\n",
    "                continue\n",
    "        elif code_range == str(icd_code):\n",
    "            return category_labels[category]\n",
    "    return category_labels['Q45_QO15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fe80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_merged['condition_label'] = diagnoses_merged['icd_code'].apply(classify_diagnosis)\n",
    "diagnoses_grouped = diagnoses_merged.groupby(['hadm_id', 'subject_id'])['condition_label'].apply(lambda x: ', '.join(set(x))).reset_index()\n",
    "patient_data = pd.merge(merged_data, diagnoses_grouped, on=['hadm_id', 'subject_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b46ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nies['gender'] = df_nies['Gender'].map({1: 'M', 2: 'F'})\n",
    "admission_type_map = {\n",
    "    'EU OBSERVATION': 0.0,\n",
    "    'URGENT': 0.0,\n",
    "    'EW EMER.': 1.0,\n",
    "    'SURGICAL SAME DAY ADMISSION': 0.0,\n",
    "    'DIRECT EMER.': 0.0\n",
    "}\n",
    "patient_data['AdmTypeBinary'] = patient_data['admission_type'].map(admission_type_map).fillna(0.0)\n",
    "nies_avg_scores = df_nies.groupby(['AdmTypeBinary', 'gender', 'condition_label'])['satisfaction_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e088432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = patient_data.assign(condition_label=patient_data['condition_label'].str.split(', ')).explode('condition_label')\n",
    "patient_data = pd.merge(\n",
    "    patient_data,\n",
    "    nies_avg_scores,\n",
    "    left_on=['AdmTypeBinary', 'gender', 'condition_label'],\n",
    "    right_on=['AdmTypeBinary', 'gender', 'condition_label'],\n",
    "    how='left'\n",
    ")\n",
    "patient_data = patient_data.groupby(['hadm_id', 'subject_id', 'admission_type', 'insurance', 'gender', 'anchor_age', 'AdmTypeBinary'])['satisfaction_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5280276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures_merged = pd.merge(patient_data, df_procedures_icd, on=['hadm_id', 'subject_id'], how='left')\n",
    "procedures_merged = procedures_merged.dropna(subset=['icd_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e501cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_procedures = set()\n",
    "for codes in procedures_merged['icd_code'].dropna():\n",
    "    all_procedures.add(str(codes))\n",
    "matrix = pd.pivot_table(\n",
    "    procedures_merged,\n",
    "    values='satisfaction_score',\n",
    "    index=['hadm_id', 'subject_id', 'gender', 'anchor_age', 'admission_type', 'insurance'],\n",
    "    columns='icd_code',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7.1_collaborative_filtering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Collaborative Filtering (User-User)\n",
    "def collaborative_filtering_recommendations(matrix, patient_idx, n_neighbors=5, n_recommendations=5):\n",
    "    patient_features = matrix.reset_index()[['gender', 'anchor_age', 'admission_type', 'insurance']]\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_features = encoder.fit_transform(patient_features[['gender', 'admission_type', 'insurance']])\n",
    "    scaler = StandardScaler()\n",
    "    scaled_age = scaler.fit_transform(patient_features[['anchor_age']])\n",
    "    patient_features_combined = np.hstack([encoded_features, scaled_age])\n",
    "    similarity_matrix = cosine_similarity(patient_features_combined)\n",
    "    similarities = similarity_matrix[patient_idx]\n",
    "    neighbor_indices = np.argsort(similarities)[-n_neighbors-1:-1][::-1]\n",
    "    neighbor_procedures = matrix.iloc[neighbor_indices].mean(axis=0)\n",
    "    patient_procedures = matrix.iloc[patient_idx]\n",
    "    neighbor_procedures[patient_procedures > 0] = 0\n",
    "    recommendations = neighbor_procedures.sort_values(ascending=False).head(n_recommendations)\n",
    "    return recommendations.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7.2_matrix_factorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Matrix Factorization (SVD)\n",
    "def svd_recommendations(matrix, n_components=10, n_recommendations=5):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    matrix_sparse = csr_matrix(matrix.values)\n",
    "    latent_factors = svd.fit_transform(matrix_sparse)\n",
    "    reconstructed_matrix = np.dot(latent_factors, svd.components_)\n",
    "    recommendations = []\n",
    "    for patient_idx in range(matrix.shape[0]):\n",
    "        predicted_scores = reconstructed_matrix[patient_idx]\n",
    "        patient_procedures = matrix.iloc[patient_idx]\n",
    "        predicted_scores[patient_procedures > 0] = 0\n",
    "        top_procedures = np.argsort(predicted_scores)[-n_recommendations:][::-1]\n",
    "        recommendations.append(matrix.columns[top_procedures].tolist())\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7.3_content_based",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Content-Based Filtering\n",
    "def content_based_recommendations(procedures_merged, df_d_icd_procedures, n_recommendations=5):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    procedure_texts = df_d_icd_procedures['long_title'].fillna('')\n",
    "    tfidf_matrix = tfidf.fit_transform(procedure_texts)\n",
    "    code_to_idx = {code: idx for idx, code in enumerate(df_d_icd_procedures['icd_code'])}\n",
    "    recommendations = []\n",
    "    for _, patient in procedures_merged.groupby(['hadm_id', 'subject_id']):\n",
    "        patient_procedures = patient['icd_code'].values\n",
    "        patient_vectors = np.zeros(tfidf_matrix.shape[1])\n",
    "        valid_procedures = 0\n",
    "        for proc in patient_procedures:\n",
    "            if proc in code_to_idx:\n",
    "                patient_vectors += tfidf_matrix[code_to_idx[proc]].toarray()[0]\n",
    "                valid_procedures += 1\n",
    "        if valid_procedures > 0:\n",
    "            patient_vectors /= valid_procedures\n",
    "        similarities = cosine_similarity([patient_vectors], tfidf_matrix)[0]\n",
    "        top_indices = np.argsort(similarities)[-n_recommendations-1:-1][::-1]\n",
    "        rec_procedures = df_d_icd_procedures.iloc[top_indices]['icd_code'].tolist()\n",
    "        recommendations.append(rec_procedures)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7.4_nmf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4: NMF (Non-negative Matrix Factorization)\n",
    "def nmf_recommendations(matrix, n_components=10, n_recommendations=5):\n",
    "    nmf = NMF(n_components=n_components, init='random', random_state=42)\n",
    "    matrix_sparse = csr_matrix(matrix.values)\n",
    "    W = nmf.fit_transform(matrix_sparse)\n",
    "    H = nmf.components_\n",
    "    reconstructed_matrix = np.dot(W, H)\n",
    "    recommendations = []\n",
    "    for patient_idx in range(matrix.shape[0]):\n",
    "        predicted_scores = reconstructed_matrix[patient_idx]\n",
    "        patient_procedures = matrix.iloc[patient_idx]\n",
    "        predicted_scores[patient_procedures > 0] = 0\n",
    "        top_procedures = np.argsort(predicted_scores)[-n_recommendations:][::-1]\n",
    "        recommendations.append(matrix.columns[top_procedures].tolist())\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "evaluation_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "def evaluate_recommendations(matrix, recommendations, test_matrix):\n",
    "    rmse, mae, hit_count, total = 0, 0, 0, 0\n",
    "    for i in range(len(recommendations)):\n",
    "        actual = test_matrix.iloc[i]\n",
    "        actual_procedures = actual[actual > 0].index.tolist()\n",
    "        if not actual_procedures:\n",
    "            continue\n",
    "        predicted = recommendations[i]\n",
    "        predicted_scores = np.zeros(len(matrix.columns))\n",
    "        for proc in predicted:\n",
    "            if proc in matrix.columns:\n",
    "                predicted_scores[matrix.columns.get_loc(proc)] = 1\n",
    "        actual_scores = actual.values\n",
    "        mse = mean_squared_error(actual_scores, predicted_scores)\n",
    "        rmse += np.sqrt(mse)\n",
    "        mae += mean_absolute_error(actual_scores, predicted_scores)\n",
    "        hits = len(set(predicted).intersection(set(actual_procedures)))\n",
    "        hit_count += hits\n",
    "        total += 1\n",
    "    rmse = rmse / total if total > 0 else 0\n",
    "    mae = mae / total if total > 0 else 0\n",
    "    hit_rate = hit_count / total if total > 0 else 0\n",
    "    satisfaction_lift = []\n",
    "    for i, recs in enumerate(recommendations):\n",
    "        patient_scores = matrix.iloc[i]\n",
    "        rec_scores = [patient_scores[matrix.columns.get_loc(proc)] for proc in recs if proc in matrix.columns and patient_scores[matrix.columns.get_loc(proc)] > 0]\n",
    "        if rec_scores:\n",
    "            satisfaction_lift.append(np.mean(rec_scores) - patient_scores[patient_scores > 0].mean())\n",
    "    mean_satisfaction_lift = np.mean(satisfaction_lift) if satisfaction_lift else 0\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'Hit Rate': hit_rate, 'Mean Satisfaction Lift': mean_satisfaction_lift}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Procedure-to-Procedure Transition Heatmap\n",
    "def plot_transition_heatmap(matrix):\n",
    "    transition_matrix = np.zeros((len(matrix.columns), len(matrix.columns)))\n",
    "    for i in range(len(matrix)):\n",
    "        procedures = matrix.iloc[i]\n",
    "        proc_indices = np.where(procedures > 0)[0]\n",
    "        for j in proc_indices:\n",
    "            for k in proc_indices:\n",
    "                if j != k:\n",
    "                    transition_matrix[j, k] += procedures.iloc[j]\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(transition_matrix, xticklabels=matrix.columns, yticklabels=matrix.columns, cmap='Blues')\n",
    "    plt.title('Procedure-to-Procedure Transition Effectiveness')\n",
    "    plt.xlabel('Procedure')\n",
    "    plt.ylabel('Procedure')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "run_recommendations",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Run Collaborative Filtering\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cf_recommendations \u001b[38;5;241m=\u001b[39m [collaborative_filtering_recommendations(train_matrix, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_matrix))]\n\u001b[1;32m----> 8\u001b[0m cf_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcf_recommendations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollaborative Filtering Metrics:\u001b[39m\u001b[38;5;124m'\u001b[39m, cf_metrics)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Run SVD\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m, in \u001b[0;36mevaluate_recommendations\u001b[1;34m(matrix, recommendations, test_matrix)\u001b[0m\n\u001b[0;32m      3\u001b[0m rmse, mae, hit_count, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(recommendations)):\n\u001b[1;32m----> 5\u001b[0m     actual \u001b[38;5;241m=\u001b[39m \u001b[43mtest_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m     actual_procedures \u001b[38;5;241m=\u001b[39m actual[actual \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actual_procedures:\n",
      "File \u001b[1;32mc:\\Users\\Harishankar\\miniconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Harishankar\\miniconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Harishankar\\miniconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Split data for evaluation (80% train, 20% test)\n",
    "train_indices = np.random.rand(len(matrix)) < 0.8\n",
    "train_matrix = matrix.iloc[train_indices].copy()\n",
    "test_matrix = matrix.iloc[~train_indices].copy()\n",
    "\n",
    "# Run Collaborative Filtering\n",
    "cf_recommendations = [collaborative_filtering_recommendations(train_matrix, i) for i in range(len(train_matrix))]\n",
    "cf_metrics = evaluate_recommendations(train_matrix, cf_recommendations, test_matrix)\n",
    "print('Collaborative Filtering Metrics:', cf_metrics)\n",
    "\n",
    "# Run SVD\n",
    "svd_recs = svd_recommendations(train_matrix)\n",
    "svd_metrics = evaluate_recommendations(train_matrix, svd_recs, test_matrix)\n",
    "print('SVD Metrics:', svd_metrics)\n",
    "\n",
    "# Run Content-Based Filtering\n",
    "cb_recs = content_based_recommendations(procedures_merged, df_d_icd_procedures)\n",
    "cb_metrics = evaluate_recommendations(train_matrix, cb_recs[:len(train_matrix)], test_matrix)\n",
    "print('Content-Based Metrics:', cb_metrics)\n",
    "\n",
    "# Run NMF\n",
    "nmf_recs = nmf_recommendations(train_matrix)\n",
    "nmf_metrics = evaluate_recommendations(train_matrix, nmf_recs, test_matrix)\n",
    "print('NMF Metrics:', nmf_metrics)\n",
    "\n",
    "# Plot heatmap\n",
    "plot_transition_heatmap(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156c099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
